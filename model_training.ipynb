{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab4afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('data/processed_df.csv'):\n",
    "    df = pd.read_csv('data/processed_df.csv')\n",
    "    print('csv file successfully loaded!')\n",
    "else:\n",
    "    raise FileNotFoundError('File Not Found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['selling_price_scaled'].copy() # target output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bec8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping target output from the dataset\n",
    "x = df.drop(columns=['selling_price','selling_price_scaled','name']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a08cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold\n",
    "from sklearn.linear_model import Ridge,Lasso,LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler,PolynomialFeatures,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e142214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits the dataset into training and testing sets - helps in model evaluation \n",
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    x,y,test_size=0.20,random_state=42\n",
    ")\n",
    "x_train.to_parquet('data/x_train.parquet',index=False)\n",
    "x_test.to_parquet('data/x_test.parquet',index=False)\n",
    "y_train.to_frame('y_train').to_parquet('data/y_train.parquet')\n",
    "y_train.to_frame('y_test').to_parquet('data/y_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = x_train.select_dtypes(include='number').columns\n",
    "category_cols = x_train.select_dtypes(include='object').columns.astype(str)\n",
    "\n",
    "# 1. pipeline for numerical data - performs standardization,imputation and polynomial feature engineering\n",
    "num_preprocessor = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='median')),\n",
    "    ('scaler',RobustScaler()),\n",
    "    ('poly',PolynomialFeatures(include_bias=False))\n",
    "])\n",
    "\n",
    "# 2. pipeline for categorical data - performs imputation and one hot encoding\n",
    "cat_preprocessor = Pipeline(steps=[\n",
    "    ('simpute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3. column transformations - transforms individual columns based on specifications in pipelines 1 and 2\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',num_preprocessor,numeric_cols),\n",
    "    ('cat',cat_preprocessor,category_cols)\n",
    "])\n",
    "\n",
    "#cross validation split - model evaluation technique 1\n",
    "# - splits the training set into 5, trains on 4 sets and validates on 1 set, repeating the process 5 times\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "models_grid = {\n",
    "    'linear_regression' : LinearRegression(n_jobs=-1),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2,3,4]\n",
    "    },\n",
    "    'lasso' : Lasso(random_state=42),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2],\n",
    "        'classifier__alpha' : [0.1,0.5,1.0,10,50],\n",
    "        'classifier__max_iter' : [1000,1500,2000]\n",
    "    },\n",
    "    'ridge' : Ridge(random_state=42),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2],\n",
    "        'classifier__alpha' : [0.1,0.5,1.0,10,50],\n",
    "        'classifier__max_iter' : [1000,1500,2000]\n",
    "    },\n",
    "    'decision_tree_regressor' : DecisionTreeRegressor()\n",
    "}\n",
    "\n",
    "# 4. pipeline for model - XGBRegressor\n",
    "pipe_xgb = Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('model',XGBRegressor(objective='reg:squarederror',verbosity=0,random_state=42))\n",
    "])\n",
    "\n",
    "# hyperparameter tuning - model evaluation technique 5\n",
    "xgb_params_dist = {\n",
    "    'preprocessor__num__poly__degree' : [1,2],\n",
    "    'model__learning_rate' : [0.05,0.1,0.5],\n",
    "    'model__n_estimators' :[80,100],\n",
    "    'model__max_depth' : [3,6,8],\n",
    "    'model__colsample_bytree' : [0.6,0.8,1.0],\n",
    "    'model__subsample' : [0.6,0.8,1.0]\n",
    "}\n",
    "\n",
    "# gridsearchcv - uses all possible combinations in \n",
    "# hyperparameter tuning to train the model, chooses the best combination\n",
    "gs_xgb = GridSearchCV(estimator=pipe_xgb,\n",
    "                            param_grid=xgb_params_dist,\n",
    "                            cv = cv,\n",
    "                            n_jobs= -1,\n",
    "                            return_train_score=True,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            refit=True,\n",
    "                            verbose=2)\n",
    "\n",
    "# model training\n",
    "print('Fitting GridSearchCV for xgboost (This may take a while)...')\n",
    "gs_xgb.fit(x_train,y_train)\n",
    "print('Best parameters: ',gs_xgb.best_params_) #returns the best parameters - (best combination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
