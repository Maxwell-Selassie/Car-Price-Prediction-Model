{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab4afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('data/processed_df.csv'):\n",
    "    df = pd.read_csv('data/processed_df.csv')\n",
    "    print('csv file successfully loaded!')\n",
    "else:\n",
    "    raise FileNotFoundError('File Not Found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf39cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['selling_price_scaled'].copy() # target output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bec8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping target output from the dataset\n",
    "x = df.drop(columns=['selling_price','selling_price_scaled','name']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a08cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold\n",
    "from sklearn.linear_model import Ridge,Lasso,LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler,PolynomialFeatures,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e142214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits the dataset into training and testing sets - helps in model evaluation \n",
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    x,y,test_size=0.20,random_state=42\n",
    ")\n",
    "x_train.to_parquet('data/x_train.parquet',index=False)\n",
    "x_test.to_parquet('data/x_test.parquet',index=False)\n",
    "y_train.to_frame('y_train').to_parquet('data/y_train.parquet')\n",
    "y_test.to_frame('y_test').to_parquet('data/y_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = x_train.select_dtypes(include='number').columns\n",
    "category_cols = x_train.select_dtypes(include='object').columns.astype(str)\n",
    "\n",
    "# 1. pipeline for numerical data - performs standardization,imputation and polynomial feature engineering\n",
    "num_preprocessor = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='median')),\n",
    "    ('scaler',RobustScaler()),\n",
    "    ('poly',PolynomialFeatures(include_bias=False))\n",
    "])\n",
    "\n",
    "# 2. pipeline for categorical data - performs imputation and one hot encoding\n",
    "cat_preprocessor = Pipeline(steps=[\n",
    "    ('simpute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3. column transformations - transforms individual columns based on specifications in pipelines 1 and 2\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',num_preprocessor,numeric_cols),\n",
    "    ('cat',cat_preprocessor,category_cols)\n",
    "])\n",
    "\n",
    "#cross validation split \n",
    "# - splits the training set into 5, trains on 4 sets and validates on 1 set, repeating the process 5 times\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "# hyperparameter tuning \n",
    "models_grid = {\n",
    "    'xgb_regressor' : {'model' : XGBRegressor(objective='reg:squarederror',random_state=42),\n",
    "    'params' : {\n",
    "    'classifier__learning_rate' : [0.03,0.05,0.08],\n",
    "    'classifier__n_estimators' :[80,100,120],\n",
    "    'classifier__max_depth' : [6,8,10],\n",
    "    'classifier__min_samples_split' : [3,4,7],\n",
    "    'classifier__reg_lambda' : [0.2,0.4,0.6,0.8]\n",
    "}},\n",
    "    'Linear_regression' : {'model' : LinearRegression(n_jobs=-1),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2,3,4]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'Lasso' : {'model' : Lasso(random_state=42),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2],\n",
    "        'classifier__alpha' : [0.1,0.5,1.0,10,50],\n",
    "        'classifier__max_iter' : [1000,1500,2000]\n",
    "    }},\n",
    "\n",
    "    'Ridge': {'model' : Ridge(random_state=42),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2],\n",
    "        'classifier__alpha' : [0.1,0.5,1.0,10,50],\n",
    "        'classifier__max_iter' : [1000,1500,2000]\n",
    "    }},\n",
    "\n",
    "    'decision_tree' : {'model' : DecisionTreeRegressor(random_state=42),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2],\n",
    "        'classifier__max_depth' : [4,6,8,None],\n",
    "        'classifier__min_samples_split' : [2,4,8]\n",
    "    }},\n",
    "\n",
    "    'random_forest' : {'model' : RandomForestRegressor(n_jobs=-1,random_state=42),\n",
    "    'params' : {\n",
    "        'preprocessor__num__poly__degree' : [1,2],\n",
    "        'classifier__max_depth' : [4,6,8,None],\n",
    "        'classifier__min_samples_split' : [2,4,8]\n",
    "    }}\n",
    "}\n",
    "\n",
    "best_score = -float('inf')\n",
    "best_model_name = None\n",
    "best_estimator = None\n",
    "\n",
    "result = {}\n",
    "# 4. pipeline for model\n",
    "for name,models in models_grid.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor',preprocessor),\n",
    "        ('classifier',models['model'])\n",
    "    ])\n",
    "\n",
    "    # gridsearchcv - uses all possible combinations in \n",
    "    # hyperparameter tuning to train the model, chooses the best combination\n",
    "    model = GridSearchCV(estimator=pipe,\n",
    "                            param_grid=models['params'],\n",
    "                            cv = cv,\n",
    "                            n_jobs= -1,\n",
    "                            return_train_score=True,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            refit=True,\n",
    "                            verbose=2)\n",
    "\n",
    "    # model training\n",
    "    print(f'Fitting GridSearchCV for {name} (This may take a while)...')\n",
    "    model.fit(x_train,y_train)\n",
    "    print('\\n','-'*50,'\\n')\n",
    "\n",
    "    result[name] = {\n",
    "        'best_score' : model.best_score_,\n",
    "        'best_params' : model.best_params_\n",
    "    }\n",
    "    if model.best_score_ > best_score:\n",
    "        best_score = model.best_score_\n",
    "        best_model_name = name\n",
    "        best_estimator = model.best_estimator_\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(model.best_estimator_,f'models/{name}_best_model.pkl')\n",
    "\n",
    "    import json\n",
    "    with open('models/results_summary','w') as file:\n",
    "        json.dump(result,file,indent=4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
